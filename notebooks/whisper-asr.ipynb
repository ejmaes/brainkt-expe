{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription using OpenAI Whisper\n",
    "Documentation on how to install Whisper is on the [OpenAI GitHub Page](https://github.com/openai/whisper) | [Colab example](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb#scrollTo=-YcRU5jqNqo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt install ffmpeg mediainfo sox libsox-fmt-mp3\n",
    "!brew install ffmpeg\n",
    "!brew install sox\n",
    "!brew install mediainfo\n",
    "!pip install audiofile\n",
    "!pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/kr/m6yb8cr154dcdkxnm75b4clw0000gn/T/pip-req-build-v8ztzydv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/kr/m6yb8cr154dcdkxnm75b4clw0000gn/T/pip-req-build-v8ztzydv\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from whisper==1.0) (1.22.3)\n",
      "Requirement already satisfied: torch in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from whisper==1.0) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from whisper==1.0) (4.64.0)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "Collecting transformers>=4.19.0\n",
      "  Using cached transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: requests in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2.tar.gz (359 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.1/359.1 kB\u001b[0m \u001b[31m971.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp310-cp310-macosx_11_0_arm64.whl (287 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 kB\u001b[0m \u001b[31m833.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/eliot/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.0)\n",
      "Building wheels for collected packages: whisper, tokenizers\n",
      "  Building wheel for whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175217 sha256=028d156e2a709533d9d7090640eac36807f838012ebcf30cf204e03a0c9d6310\n",
      "  Stored in directory: /private/var/folders/kr/m6yb8cr154dcdkxnm75b4clw0000gn/T/pip-ephem-wheel-cache-07dq2a5k/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[51 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer.py -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.macosx-11.1-arm64-cpython-310/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully built whisper\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ffmpeg` can be used to [extract audio from the video](https://stackoverflow.com/questions/9913032/how-can-i-extract-audio-from-video-with-ffmpeg): \n",
    "```\n",
    "ffmpeg -i ~/Downloads/tmp/bkt-pilot-221103.mov -ss 00:00:00 -t 00:00:45.0 -q:a 0 -map a ~/Downloads/tmp/1minaudio.mp3\n",
    "```\n",
    "\n",
    "In our case, `whisper` can be called from the command line, with the output:\n",
    "```bash\n",
    "(base) eliot@Eliots-MBP aclpubcheck % whisper ~/Downloads/tmp/1minaudio.mp3 --language French\n",
    "100%|████████████████████████████████████████| 461M/461M [09:57<00:00, 809kiB/s]\n",
    "/Users/eliot/miniconda3/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
    "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "[00:00.000 --> 00:13.320]  Donc qu'est ce que tu as comme module comme petit carré? Il y a une horloge à côté de l'horloge\n",
    "[00:13.320 --> 00:24.840]  et il y a une espèce de balise avec un chronomètre et il y a un bouton annulé il y a quatre\n",
    "[00:24.840 --> 00:30.840]  boutons rouge bleu vert et jeune rouge bleu vert jeune on va aller là dessus je clique sur cela\n",
    "[00:30.840 --> 00:41.400]  alors ça s'appelle un saimon saimon 16 donc un des quatre boutons va s'allumer oui voilà quel\n",
    "[00:41.400 --> 01:11.400]  bouton s'allumer et jeune dans ce cas\n",
    "```\n",
    "\n",
    "Downsides:\n",
    "* Loose audio boundaries\n",
    "* No distinctions between channels\n",
    "\n",
    "Steps need to be taken to split between channels and align the transcription to IPUs/Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audiofile\n",
    "!pip install textgrid\n",
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import shutil\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import audiofile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "from glob import glob\n",
    "import textgrid\n",
    "import shutil\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "\n",
    "# google timeout\n",
    "import requests\n",
    "from requests import ConnectionError\n",
    "import xml.etree.ElementTree as ET\n",
    "import ffmpeg\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# SPPAS\n",
    "SPPAS_PATH = \"/Users/eliot/Documents/tools/SPPAS\"\n",
    "sys.path.append(SPPAS_PATH)\n",
    "# reading / writing textgrids\n",
    "import sppas.src.anndata.aio.readwrite as spp\n",
    "import sppas.src.anndata as sad\n",
    "# searching for IPUs\n",
    "import sppas\n",
    "from sppas.src.annotations import sppasParam, sppasAnnotationsManager\n",
    "from sppas.src.plugins import sppasPluginsManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the model (Python)\n",
    "* [Audio resampling in Python](https://github.com/jonashaag/audio-resampling-in-python)\n",
    "* Paths with SPPAS: counts relatively from where the software is stored, no absolute paths\n",
    "* `RuntimeError: \"slow_conv2d_cpu\" not implemented for 'Half' #92` for [whisper](https://github.com/openai/whisper/discussions/92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "#from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel(audio, device=DEVICE):\n",
    "    audio = whisper.pad_or_trim(audio.flatten()).to(device) \n",
    "    # docstring: whisper.pad_or_trim(array, length: int = 480000, *, axis: int = -1)\n",
    "    mel = whisper.log_mel_spectrogram(audio)\n",
    "    return mel\n",
    "\n",
    "def resample_audio(audio, orig_fs:int, target_fq:int=16000, device=DEVICE):\n",
    "    if not isinstance(audio, torch.Tensor):\n",
    "        audio = torch.Tensor(audio, device=device)\n",
    "    # resample\n",
    "    rs = torchaudio.transforms.Resample(orig_freq=orig_fs, new_freq=target_fq)\n",
    "    return rs(audio)\n",
    "\n",
    "class AudioFileDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filepath, device=DEVICE, fs_th:int=16000, cleanup_after_splitting:bool=False):\n",
    "        self.filepath = filepath if filepath[0] != '~' else os.path.expanduser(filepath)\n",
    "        self.audio_duration = audiofile.duration(filepath)\n",
    "        self.audio, self.fs = audiofile.read(filepath, always_2d=True)\n",
    "        self.nb_channels = audiofile.channels(filepath)\n",
    "        self.save_folder = os.path.realpath(os.path.dirname(self.filepath))\n",
    "        self.filename = self.filepath.split('/')[-1]\n",
    "        self.device = device\n",
    "        self.cleanup_onechannel = cleanup_after_splitting\n",
    "        print(f\"File {filepath}: {self.nb_channels} channels, sampling frequency = {self.fs}Hz, {self.audio_duration}s\")\n",
    "        print('Creating dataset...', end=' ')\n",
    "        if self.fs != fs_th:\n",
    "            self._resample(target_fq=fs_th)\n",
    "        self.ipus_bounds = self._searchipus()\n",
    "        self._create_dataset()\n",
    "        self.datasets = {'base':self.dataset}\n",
    "        print('done.')\n",
    "\n",
    "    def _resample(self, target_fq:int=16000):\n",
    "        # to tensor + resample\n",
    "        self.or_audio = self.audio\n",
    "        self.audio = resample_audio(self.audio, self.fs, target_fq, device=self.device)\n",
    "\n",
    "    def _searchipus(self):\n",
    "        \"\"\"For each channel, locate IPUs using SPPAS. \n",
    "        1. SPPAS creates new files \n",
    "        2. read from those files then delete them\n",
    "        \"\"\"\n",
    "        # SPPAS - activate\n",
    "        spass_log=f\"searchipus-{datetime.datetime.now().strftime('%y%m%d-%H:%M:%S')}-{self.filepath}\"\n",
    "        actions = ['searchipus']\n",
    "        parameters = sppasParam([f\"{x}.json\" for x in actions])\n",
    "        for x in actions:\n",
    "            ann_step_idx = parameters.activate_annotation(x)\n",
    "            ann_options = parameters.get_options(ann_step_idx)\n",
    "\n",
    "        # Files - for each channel\n",
    "        for c in range(self.nb_channels):\n",
    "            # extract sound and create a new file\n",
    "            ns = self.audio[c,:]\n",
    "            ns_path = os.path.join(self.save_folder, f\"{self.filename[:-4]}_mono_{c}.wav\")\n",
    "            audiofile.write(ns_path, ns, self.fs)\n",
    "            parameters.add_to_workspace(ns_path)\n",
    "    \n",
    "        # SPPAS - Fix the output file extension and others\n",
    "        parameters.set_lang(\"fra\")\n",
    "        parameters.set_output_extension('.TextGrid', \"ANNOT\")\n",
    "        parameters.set_report_filename(spass_log)\n",
    "        # SPPAS - Execute pipeline\n",
    "        process = sppasAnnotationsManager()\n",
    "        process.annotate(parameters)\n",
    "\n",
    "        # Files - read each file to dataset\n",
    "        ipus_bounds = []\n",
    "        for c in range(self.nb_channels):\n",
    "            # use relpath to get the relative path from SPPAS to target folder\n",
    "            # uses os.getcwd() to compute path if given in relative - os.path.expanduser() necessited\n",
    "            #self.save_folder = os.path.relpath(os.path.dirname(self.filepath), start=SPPAS_PATH)\n",
    "            ns_path = os.path.join(self.save_folder, f\"{self.filename[:-4]}_mono_{c}.wav\")\n",
    "            tg_path = f'{ns_path[:-4]}-ipus.TextGrid'\n",
    "            tg = textgrid.TextGrid.fromFile(tg_path)\n",
    "            for t in tg[0]:\n",
    "                if t.mark not in [\"#\",\"\"]: # check that\n",
    "                    ipus_bounds.append({\n",
    "                        'channel': c, 'start': t.minTime, 'stop': t.maxTime,\n",
    "                    })\n",
    "            # Files - cleanup sound and textgrid\n",
    "            if self.cleanup_onechannel:\n",
    "                os.remove(ns_path)\n",
    "                os.remove(tg_path)\n",
    "        \n",
    "        return pd.DataFrame(ipus_bounds)\n",
    "\n",
    "    def _create_dataset(self, fs:int=16000): # fs set by whisper\n",
    "        # from bounds + signal + fs, extract signal for each ipu\n",
    "        dataset = {}\n",
    "        for idx, row in tqdm(self.ipus_bounds.iterrows()):\n",
    "            dataset[idx] = [row.start, row.stop, int(row.channel), self.audio[int(row.channel), int(row.start*fs):int(row.stop*fs)]]\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def _create_long_dataset(self, maximum_pause_duration:float=3, fs:int=16000, **kwargs):\n",
    "        self.ipus_bounds['duration'] = self.ipus_bounds.stop - self.ipus_bounds.start\n",
    "        self.ipus_bounds['pause'] = (self.ipus_bounds.start.shift(-1) - self.ipus_bounds.stop).fillna(0.) # last value\n",
    "        # aggregate - need to keep it shorter than 300s\n",
    "        self.ipus_bounds['new_line'] = self.ipus_bounds['pause'] > maximum_pause_duration\n",
    "        self.ipus_bounds['new_line_idx'] = self.ipus_bounds['new_line'].cumsum()\n",
    "        ipu_concat = self.ipus_bounds.groupby(['channel','new_line_idx']).agg({ 'start': 'min', 'stop':'max' }).reset_index(drop=False)\n",
    "        # call cataset - in other variable\n",
    "        dataset = {}\n",
    "        for idx, row in tqdm(ipu_concat.iterrows()):\n",
    "            dataset[idx] = [row.start, row.stop, int(row.channel), self.audio[int(row.channel), int(row.start*fs):int(row.stop*fs)]]\n",
    "        self.datasets[f'long_{maximum_pause_duration}'] = dataset\n",
    "\n",
    "    def set_dataset(self, mode:str, **kwargs):\n",
    "        if (mode not in self.datasets) and (mode != 'long'):\n",
    "            raise ValueError('`mode` should be in [\"base\",\"long\"]')\n",
    "        if mode in self.datasets:\n",
    "            print(f'Switching to {mode}')\n",
    "            self.dataset = self.datasets[mode]\n",
    "            self.mode = mode\n",
    "        elif mode == \"long\":\n",
    "            self._create_long_dataset(**kwargs)\n",
    "            mode = f\"long_{kwargs.get('maximum_pause_duration',3) }\"\n",
    "            print(f'Switching to concatenated IPUs - {mode}')\n",
    "            self.dataset = self.datasets[mode]\n",
    "            self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        start, stop, channel, audio = self.dataset[item]\n",
    "        if not isinstance(audio, torch.Tensor):\n",
    "            audio = torch.Tensor(audio, device=self.device)\n",
    "        mel = get_mel(audio, device=self.device)\n",
    "        return start, stop, channel, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ~/Downloads/tmp/bkt-pilot-221103-audio.wav: 2 channels, sampling frequency = 16000Hz, 2703.68s\n",
      "Creating dataset... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1237it [00:00, 23680.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"~/Downloads/tmp/bkt-pilot-221103-audio.wav\"\n",
    "dataset = AudioFileDataset(filepath)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "options = whisper.DecodingOptions(language=\"fr\", without_timestamps=False, fp16 = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, stop, channel, mels = dataset[0]\n",
    "results = model.decode(mels, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [12:22<00:00, 18.57s/it]\n"
     ]
    }
   ],
   "source": [
    "transcr = {'start':[], 'stop':[], 'channel':[], 'text': []}\n",
    "for start, stop, channel, mels in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    ### nope batch\n",
    "    # if 'text' in dir(results):\n",
    "    #     text = results.text\n",
    "    # else:\n",
    "    #     text = ' '.join([result.text for result in results])\n",
    "    # transcr.append({ 'channel': channel, 'start':start, 'stop':stop, 'text': text })\n",
    "    ### batch >> extend\n",
    "    for k,v in zip(['start','stop','channel','text'],[start, stop, channel, [result.text for result in results]]):\n",
    "        if not isinstance(v,list):\n",
    "            v = v.tolist()\n",
    "        transcr[k].extend(v)\n",
    "\n",
    "transcr = pd.DataFrame(transcr)\n",
    "#transcr['start'] = transcr.start.apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.375</td>\n",
       "      <td>2.215</td>\n",
       "      <td>0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.715</td>\n",
       "      <td>5.060</td>\n",
       "      <td>0</td>\n",
       "      <td>donc, qui se tracent à mouge?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.190</td>\n",
       "      <td>10.355</td>\n",
       "      <td>0</td>\n",
       "      <td>carré. Il y a une horloge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.975</td>\n",
       "      <td>11.985</td>\n",
       "      <td>0</td>\n",
       "      <td>à cause de la tronte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.205</td>\n",
       "      <td>13.065</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    stop  channel                           text\n",
       "0   1.375   2.215        0                             ok\n",
       "1   2.715   5.060        0  donc, qui se tracent à mouge?\n",
       "2   6.190  10.355        0     carré. Il y a une horloge.\n",
       "3  10.975  11.985        0          à cause de la tronte.\n",
       "4  12.205  13.065        0                            ..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results aren't very good \n",
    "* option 1: try with model other than `'base'` \n",
    "* option 2: try with longer audios\n",
    "* option 3: issue with resampling that needs to be done before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: with heavier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [24:33<00:00, 1.04MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# available models: tiny base small medium large\n",
    "# default setting from command line: using 'small' model\n",
    "model = whisper.load_model(\"medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [1:59:45<00:00, 179.64s/it]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.375</td>\n",
       "      <td>2.215</td>\n",
       "      <td>0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.715</td>\n",
       "      <td>5.060</td>\n",
       "      <td>0</td>\n",
       "      <td>donc, qui se tracent à mouge?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.190</td>\n",
       "      <td>10.355</td>\n",
       "      <td>0</td>\n",
       "      <td>carré. Il y a une horloge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.975</td>\n",
       "      <td>11.985</td>\n",
       "      <td>0</td>\n",
       "      <td>à cause de la tronte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.205</td>\n",
       "      <td>13.065</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    stop  channel                           text\n",
       "0   1.375   2.215        0                             ok\n",
       "1   2.715   5.060        0  donc, qui se tracent à mouge?\n",
       "2   6.190  10.355        0     carré. Il y a une horloge.\n",
       "3  10.975  11.985        0          à cause de la tronte.\n",
       "4  12.205  13.065        0                            ..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = {'start':[], 'stop':[], 'channel':[], 'text': []}\n",
    "for start, stop, channel, mels in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    for k,v in zip(['start','stop','channel','text'],[start, stop, channel, [result.text for result in results]]):\n",
    "        if not isinstance(v,list):\n",
    "            v = v.tolist()\n",
    "        t2[k].extend(v)\n",
    "\n",
    "t2 = pd.DataFrame(transcr)\n",
    "t2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: with longer extracts\n",
    "* Either configuring SPPAS differently for the IPUs\n",
    "* Or using longer audio sequences in the model (max: 480000 / 16000 = 300 seconds)\n",
    "\n",
    "Whisper can be used directly to transcribe. [From Doc] Internally, the `transcribe()` method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring SPPAS differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spass_log=f\"searchipus-{datetime.datetime.now().strftime('%y%m%d-%H:%M:%S')}-{self.filepath}\"\n",
    "actions = ['searchipus']\n",
    "parameters = sppasParam([f\"{x}.json\" for x in actions])\n",
    "for x in actions:\n",
    "    ann_step_idx = parameters.activate_annotation(x)\n",
    "    ann_options = parameters.get_options(ann_step_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sppas.src.structs.baseoption.sppasOption at 0x13a0c6d00>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_options[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using longer sequences of audio (using window):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 43259200])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_duration = audiofile.duration(filepath)\n",
    "audio, fs = audiofile.read(filepath, always_2d=True)\n",
    "nb_channels = audiofile.channels(filepath)\n",
    "audio = resample_audio(audio, fs)\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_extract(model, audio, s_start:float=0., s_stop:float=300., channel:int=0, \n",
    "            device=DEVICE, model_options=whisper.DecodingOptions()):\n",
    "    fs = 16000\n",
    "    audio = audio[channel, int(s_start*fs):int(s_stop*fs)]\n",
    "    mel = get_mel(audio, device)\n",
    "    results = model.decode(mel, model_options)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predict_extract(model, audio, model_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecodingResult(audio_features=tensor([[-1.2868e-01,  7.4106e-01, -1.8666e-01,  ...,  3.0302e-01,\n",
       "          3.1401e-01,  1.4705e+00],\n",
       "        [ 2.8794e-02,  4.5873e-01,  3.7895e-01,  ...,  3.5652e-03,\n",
       "         -1.7153e-01,  8.3642e-01],\n",
       "        [ 1.8124e-01,  2.4811e-02,  2.5020e-01,  ..., -3.3304e-01,\n",
       "         -4.4838e-01,  2.3060e-01],\n",
       "        ...,\n",
       "        [ 3.0571e-01,  3.7052e-01,  3.0373e-01,  ...,  3.4993e-01,\n",
       "         -3.4388e-01,  1.5461e+00],\n",
       "        [-4.0124e-01,  8.9956e-01,  8.0569e-01,  ...,  2.0286e+00,\n",
       "         -1.8074e-03,  1.3847e+00],\n",
       "        [-1.1076e+00,  5.8126e-01,  1.3918e+00,  ...,  1.7550e+00,\n",
       "         -9.9986e-01,  1.0190e+00]]), language='fr', language_probs=None, tokens=[50364, 7477, 421, 6, 377, 1769, 631, 2604, 382, 5173, 10088, 11, 5173, 9686, 1032, 10521, 2506, 50688, 50688, 4416, 288, 257, 2251, 2569, 752, 432, 1531, 18437, 368, 287, 6, 2335, 752, 432, 1030, 1930, 288, 257, 2251, 7089, 30236, 368, 3119, 908, 4163, 517, 19393, 298, 1462, 3599, 51508, 51508, 1030, 1930, 288, 257, 517, 15738, 266, 2324, 425, 526, 1030, 1930, 288, 257, 31334, 15738, 892, 40605, 11, 5408, 84, 11, 6509, 1030, 2784, 2613, 13, 51754, 51754], text=\"Donc qu'est ce que tu as comme module, comme petit carré? Il y a une horloge à côté de l'horloge et il y a une espèce de balise avec un chronomètre et il y a un bouton annulé et il y a quatre boutons rouge, bleu, vert et jaune.\", avg_logprob=-0.28261496381061835, no_speech_prob=0.36415377259254456, temperature=0.0, compression_ratio=1.4099378881987579)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Donc qu'est ce que tu as comme module, comme petit carré? Il y a une horloge à côté de l'horloge et il y a une espèce de balise avec un chronomètre et il y a un bouton annulé et il y a quatre boutons rouge, bleu, vert et jaune. Rouges, bleu, vert, jaune, on va aller là-dessus. Tu cliques sur cela. Ça s'appelle un Simon, Simon Says. Donc un des quatre boutons va s'allumer. Oui. Voilà. Quel bouton s'allumer? Jaune. Dans ce cas, déjà est-ce que tu vois le numéro de série ou pas? Un numéro. Non. Non. Clique sur vert. Est-ce que ça t'a mis quelque chose?\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(audio[1, 0:(60*16000)], fp16=False)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using longer sequences of audio (using IPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ~/Downloads/tmp/bkt-pilot-221103-audio.wav: 2 channels, sampling frequency = 16000Hz, 2703.68s\n",
      "Creating dataset... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1237it [00:00, 32883.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [00:00, 33185.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to concatenated IPUs - long_3\n",
      "284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioFileDataset(filepath)\n",
    "dataset.set_dataset(\"long\")\n",
    "print(len(dataset.dataset))\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [1:17:21<00:00, 257.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.185</td>\n",
       "      <td>12.365</td>\n",
       "      <td>0</td>\n",
       "      <td>Il y a une horloge, il est 10h31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.900</td>\n",
       "      <td>22.670</td>\n",
       "      <td>0</td>\n",
       "      <td>et il a une espèce de balise avec un chronomètre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.895</td>\n",
       "      <td>27.510</td>\n",
       "      <td>0</td>\n",
       "      <td>Il y a un bouton annulé. Il y a quatre boutons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.555</td>\n",
       "      <td>42.985</td>\n",
       "      <td>0</td>\n",
       "      <td>Et je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.195</td>\n",
       "      <td>96.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Euh... Non. Non. Euh... Clique sur vert. Est-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    stop  channel                                               text\n",
       "0   8.185  12.365        0                  Il y a une horloge, il est 10h31.\n",
       "1  13.900  22.670        0  et il a une espèce de balise avec un chronomètre.\n",
       "2  22.895  27.510        0  Il y a un bouton annulé. Il y a quatre boutons...\n",
       "3  42.555  42.985        0                                           Et je...\n",
       "4  50.195  96.000        0  Euh... Non. Non. Euh... Clique sur vert. Est-c..."
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = {'start':[], 'stop':[], 'channel':[], 'text': []}\n",
    "for start, stop, channel, mels in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    for k,v in zip(['start','stop','channel','text'],[start, stop, channel, [result.text for result in results]]):\n",
    "        if not isinstance(v,list):\n",
    "            v = v.tolist()\n",
    "        t3[k].extend(v)\n",
    "\n",
    "t3 = pd.DataFrame(t3)\n",
    "t3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: longer sequences required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcr.to_csv(\"~/Downloads/tmp/bkt-pilot-221103-ipu-base.csv\", index=False)\n",
    "t2.to_csv(\"~/Downloads/tmp/bkt-pilot-221103-ipu-medium.csv\", index=False)\n",
    "t3.to_csv(\"~/Downloads/tmp/bkt-pilot-221103-agg-medium.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.185</td>\n",
       "      <td>12.365</td>\n",
       "      <td>0</td>\n",
       "      <td>Il y a une horloge, il est 10h31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.900</td>\n",
       "      <td>22.670</td>\n",
       "      <td>0</td>\n",
       "      <td>et il a une espèce de balise avec un chronomètre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.895</td>\n",
       "      <td>27.510</td>\n",
       "      <td>0</td>\n",
       "      <td>Il y a un bouton annulé. Il y a quatre boutons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.555</td>\n",
       "      <td>42.985</td>\n",
       "      <td>0</td>\n",
       "      <td>Et je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.195</td>\n",
       "      <td>96.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Euh... Non. Non. Euh... Clique sur vert. Est-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    stop  channel                                               text\n",
       "0   8.185  12.365        0                  Il y a une horloge, il est 10h31.\n",
       "1  13.900  22.670        0  et il a une espèce de balise avec un chronomètre.\n",
       "2  22.895  27.510        0  Il y a un bouton annulé. Il y a quatre boutons...\n",
       "3  42.555  42.985        0                                           Et je...\n",
       "4  50.195  96.000        0  Euh... Non. Non. Euh... Clique sur vert. Est-c..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = pd.read_csv(\"~/Downloads/tmp/bkt-pilot-221103-agg-medium.csv\")\n",
    "t3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ---------- READING ----------\n",
    "def read_tier(tg_path:str, tier_name=None) -> pd.DataFrame:\n",
    "    \"\"\"Read tier and return as DataFrame.\n",
    "    If no tier is given, returns the first tier.\n",
    "    DataFrame includes a column for the source tier.\n",
    "    \"\"\"\n",
    "    tg = textgrid.TextGrid.fromFile(tg_path)\n",
    "    # get tier names\n",
    "    tg_tiers = {tg[i].name : i for i in range(len(tg))}\n",
    "    if tier_name is None: \n",
    "        print(f\"Reading first tier from file: {tg[0].name}\")\n",
    "        tier_name = [tg[0].name]\n",
    "    elif isinstance(tier_name,str):\n",
    "        tier_name = [tier_name]\n",
    "    # read from tier\n",
    "    dialogs = []\n",
    "    for tname in tier_name:\n",
    "        tn = tg_tiers[tname]\n",
    "        tier = tg[tn]\n",
    "        for t in tier:\n",
    "            if t.mark not in [\"#\",\"\"]: # check that\n",
    "                dialogs.append({\n",
    "                    'file': tg_path.split('/')[-1],\n",
    "                    'tier': tname,\n",
    "                    'start': t.minTime,\n",
    "                    'stop': t.maxTime,\n",
    "                    'text': t.mark\n",
    "                })\n",
    "    # return\n",
    "    return pd.DataFrame(dialogs)\n",
    "\n",
    "#%% ---------- WRITING -----------\n",
    "def write_tier(df:pd.DataFrame, file_name:str, \n",
    "        example_file:str='/Users/eliot/Documents/projects/multimodal-grounding/multimodalgrounding/utils/example.TextGrid', \n",
    "        annot_tier:str='TRS', \n",
    "        text_col:str='text', timestart_col:str='start', timestop_col:str='stop',\n",
    "        file_duration:float=None, overwrite:bool=True, **kwargs):\n",
    "    \"\"\"Write data from a dataframe into a TextGrid file in intervals\n",
    "    \"\"\" \n",
    "    if os.path.exists(file_name):\n",
    "        tg = textgrid.TextGrid.fromFile(file_name)\n",
    "        tg_tiers = {tg[i].name : i for i in range(len(tg))} \n",
    "        if annot_tier in tg_tiers and overwrite:\n",
    "            print('Tier exists. Overwriting.')\n",
    "        elif (annot_tier in tg_tiers):\n",
    "            print('Tier exists. Changing tier name.')\n",
    "    # Check if there are no ipus overlapping themselves\n",
    "    overlaps = ((df[timestart_col] - df[timestop_col].shift()).dropna() < 0).sum()\n",
    "    if overlaps > 0:\n",
    "        raise IndexError(\"Overlaps between several speakers exist in this DataFrame.\")\n",
    "    # Add silence rows in DataFrame\n",
    "    stops = df[timestart_col].iloc[1:].tolist()\n",
    "    starts = df[timestop_col].iloc[:-1].tolist()\n",
    "    if df[timestart_col].iloc[0] > 0:\n",
    "        stops = [df[timestart_col].iloc[0]] + stops\n",
    "        starts = [0.0] + starts \n",
    "    if file_duration is not None:\n",
    "        stops.append(file_duration)\n",
    "        starts.append(df[timestop_col].iloc[-1])\n",
    "        print(df[timestop_col].iloc[-1])\n",
    "    df_sil = pd.DataFrame({timestart_col: starts, timestop_col: stops})\n",
    "    df_sil[text_col] = \"#\"\n",
    "    df = pd.concat([df, df_sil], axis=0).sort_values(by=[timestart_col]).reset_index(drop=True)\n",
    "    # Create / Read file\n",
    "    if os.path.exists(file_name):\n",
    "        parser = spp.sppasTrsRW(file_name)\n",
    "        tier_list = parser.read()\n",
    "    elif not os.path.exists(example_file):\n",
    "        raise ValueError(f'`example_file` argument must point to an existing file.')\n",
    "    else:\n",
    "        parser = spp.sppasTrsRW(example_file)\n",
    "        tier_list = parser.create_trs_from_extension(example_file)\n",
    "    # Create annotations\n",
    "    tier = tier_list.create_tier(annot_tier)\n",
    "    # Sequentially add rows\n",
    "    for _,row in tqdm(df.iterrows()):\n",
    "        if row[timestart_col] < row[timestop_col]: # rows throwing errors\n",
    "            # Add row\n",
    "            interval = sad.sppasInterval(sad.sppasPoint(row[timestart_col],0.0), sad.sppasPoint(row[timestop_col], 0.0))\n",
    "            tier.create_annotation(sad.sppasLocation(interval), sad.sppasLabel(sad.sppasTag(row[text_col])))\n",
    "        else:\n",
    "            print(\"\\nError printing the following row:\")\n",
    "            print(row)\n",
    "\n",
    "    parser.set_filename(file_name)\n",
    "    parser.write(tier_list)\n",
    "\n",
    "\n",
    "def write_tiers(df:pd.DataFrame, file_name:str, tier_col:str, tier_values:list=None, **kwargs) ->None:\n",
    "    \"\"\"Loop over tiers to write in the same file\n",
    "    \"\"\"\n",
    "    tier_values = tier_values if tier_values is not None else df[tier_col].unique()\n",
    "    for tier_name in tier_values:\n",
    "        write_tier(df[df[tier_col] == tier_name], file_name, annot_tier=tier_name, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:00, 7323.78it/s]\n",
      "129it [00:00, 9413.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for c in [0,1]:\n",
    "    # saving in different files to test alignment\n",
    "    write_tier(t3[t3.channel == c], file_name=os.path.join(dataset.save_folder, f\"bkt-pilot-221103-{c}.TextGrid\"), \n",
    "            annot_tier=f'spk{c}', text_column='text', timestart_col='start', timestop_col='stop',\n",
    "            file_duration=dataset.audio_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eliot/Downloads/tmp'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.save_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SPPAS\n",
    "* Pros: offline\n",
    "* Cons: need parametrizing to use 'Fill in IPUs'; other pipelines can't be used without using Tokenisation, which requires IPUs / orthographic correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BAS\n",
    "From the [BAS Documentation Page](https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/help), several pipelines are available (with -- those that interest us the most):\n",
    "```\n",
    "-- runPipelineWithASR       runCOALA                runGetVersion\n",
    "runCOALAGetTemplates        -- runASR               -- runPipeline\n",
    "runTTS                      runSubtitle             runTextEnhance\n",
    "runDoReCo                   runSpeakDiar            runVoiceActivityDetection\n",
    "runChunkPreparation         runMAUSGetInventar      runASRGetQuota\n",
    "runMINNI                    runMAUS                 getLoadIndicatorXML\n",
    "runTextAlign                runMAUSBasic            -- runPho2Syl\n",
    "getLoadIndicator            runAnnotConv            runFormantAnalysis\n",
    "runChunker                  runMAUSGetHelp          runChannelSeparator\n",
    "runTTSFile                  runAudioEnhance         runEMUMagic\n",
    "runG2P                      runGetVersion           runAnonymizer\n",
    "```\n",
    "Calling those pipelines can be done using CURL:\n",
    "```bash\n",
    "curl -v -X POST -H 'content-type: multipart/form-data' -F com=yes -F INSKANTEXTGRID=true -F USETEXTENHANCE=true -F TARGETRATE=100000 -F TEXT=@/Users/neako/Documents/Cours-MasCo/PhD/multimodalgrounding/data/EPSN/extract-transcribe/080101-000-freeConv_mono_1.TextGrid -F NOISE=0 -F PIPE=G2P_CHUNKER_MAUS_PHO2SYL -F aligner=hirschberg -F NOISEPROFILE=0 -F speakNumber=0 -F ASIGNAL=brownNoise -F NORM=true -F mauschunking=false -F INSORTTEXTGRID=true -F WEIGHT=default -F minanchorlength=3 -F LANGUAGE=eng-US -F USEAUDIOENHANCE=true -F maxlength=0 -F KEEP=false -F preference=-2.97 -F nrm=no -F LOWF=0 -F WHITESPACE_REPLACEMENT=_ -F marker=punct -F USEREMAIL=maesneako@gmail.com -F boost=true -F MINPAUSLEN=5 -F forcechunking=false -F NOINITIALFINALSILENCE=false -F minVoicedLength=200 -F InputTierName=google-annot -F OUTFORMAT=TextGrid -F syl=no -F ENDWORD=999999 -F minSilenceLength=200 -F wsync=yes -F UTTERANCELEVEL=false -F featset=standard -F INSPROB=0.0 -F OUTSYMBOL=x-sampa -F minchunkduration=15 -F SIGNAL=@/Users/neako/Documents/Cours-MasCo/PhD/multimodalgrounding/data/EPSN/extract-transcribe/080101-000-freeConv_mono_1.wav -F stress=no -F MODUS=default -F RELAXMINDUR=false -F RELAXMINDURTHREE=false -F STARTWORD=0 -F INSYMBOL=sampa -F PRESEG=false -F AWORD=ANONYMIZED -F USETRN=false -F MAUSSHIFT=default -F HIGHF=0 -F silenceonly=0 -F boost_minanchorlength=4 -F ADDSEGPROB=false 'https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/runPipeline'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bas-pipeline-config.json','r') as f: \n",
    "    gen_config = json.loads(f.read())\n",
    "\n",
    "# transform to dict and add additional parameters\n",
    "spe_config = {\n",
    "    \"InputTierName\":'spk1',\n",
    "    \"USEREMAIL\":\"maesneako@gmail.com\",\n",
    "#    \"SIGNAL\":@/Users/neako/Documents/Cours-MasCo/PhD/multimodalgrounding/data/EPSN/extract-transcribe/080101-000-freeConv_mono_1.wav,\n",
    "#    \"TEXT\":@/Users/neako/Documents/Cours-MasCo/PhD/multimodalgrounding/data/EPSN/extract-transcribe/080101-000-freeConv_mono_1.TextGrid,\n",
    "    \"LANGUAGE\":\"fra-FR\", # accepted languages: [cat, deu, eng, fin, hat, hun, ita, mlt, nld, nze, pol, aus-AU, afr-ZA, sqi-AL, arb, eus-ES, eus-FR, cat-ES, nld-NL-GN, nld-NL, nld-NL-OH, nld-NL-PR, eng-US, eng-AU, eng-GB, eng-GB-OH, eng-GB-OHFAST, eng-GB-LE, eng-SC, eng-NZ, ekk-EE, kat-GE, fin-FI, fra-FR, deu-DE, gsw-CH-BE, gsw-CH-BS, gsw-CH-GR, gsw-CH-SG, gsw-CH-ZH, gsw-CH, hat-HT, hun-HU, isl-IS, ita-IT, jpn-JP, gup-AU, sampa, ltz-LU, mlt-MT, nor-NO, fas-IR, pol-PL, ron-RO, rus-RU, slk-SK, spa-ES, swe-SE, tha-TH, guf-AU]\n",
    "}\n",
    "config = dict(gen_config, **spe_config)\n",
    "\n",
    "files = {\n",
    "    \"SIGNAL\": open(\"/Users/eliot/Downloads/tmp/bkt-pilot-221103-audio_mono_1_compressed.wav\", \"rb\"),\n",
    "    \"TEXT\": open(\"/Users/eliot/Downloads/tmp/bkt-pilot-221103-1.TextGrid\", \"rb\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = \"https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/runPipeline\"\n",
    "HEADER = {}\n",
    "response = requests.post(SOURCE_URL, files=files, data=config, headers = HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<WebServiceResponseLink><success>true</success><downloadLink>https://clarin.phonetik.uni-muenchen.de:443/BASWebServices/data/2022.11.12_18.13.37_AFC97C95669CE669DFF3A3EAAC85D499/bkt-pilot-221103-audio_mono_1_compressed.TextGrid</downloadLink><output></output><warnings></warnings></WebServiceResponseLink>'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = ET.fromstring(response.text)\n",
    "root[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600401"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_url = root[1].text #['WebServiceResponseLink']['downloadLink']\n",
    "dl_file = requests.get(file_url)\n",
    "open(\"test.TextGrid\", \"wb\").write(dl_file.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending compressed audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg.output(ffmpeg.input(\"/Users/eliot/Downloads/tmp/bkt-pilot-221103-audio_mono_1.wav\").audio, \n",
    "                \"/Users/eliot/Downloads/tmp/bkt-pilot-221103-audio_mono_1_compressed.wav\",\n",
    "                #*['sameq'],\n",
    "                ).overwrite_output().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a class running the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from bas_pipeline_analysis import AlignTranscription\n",
    "from textgrid_utils import read_tier, write_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = AlignTranscription(audio_path=\"/Users/eliot/Downloads/tmp/bkt-pilot-221103-audio_mono_1.wav\",\n",
    "    transcription_path=\"/Users/eliot/Downloads/tmp/bkt-pilot-221103-1.TextGrid\", \n",
    "    transcription_tier=\"spk1\", \n",
    "    lg='fra-FR', bas_option_path='bas-pipeline-config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.run_pipeline(compress=True) # error writing final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eliot/Downloads/tmp/bkt-pilot-221103-1-bas.TextGrid'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.aligned_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2086it [00:00, 17188.12it/s]\n"
     ]
    }
   ],
   "source": [
    "outfile = at.aligned_transcription.replace('bas','bas-ipus')\n",
    "# read file\n",
    "words = read_tier(at.aligned_transcription, tier_name=\"ORT-MAU\")\n",
    "# create ipus - columns start, stop\n",
    "words['pause_duration'] = (words['start'] - words['stop'].shift()).fillna(0.) > 0.3\n",
    "words['ipu_id'] = words['pause_duration'].cumsum()\n",
    "ipus = words.groupby('ipu_id').agg({\n",
    "    'start': 'min', 'stop': 'max', 'text': lambda x: ' '.join(list(x))\n",
    "})\n",
    "# write ipus\n",
    "write_tier(ipus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>tier</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>text</th>\n",
       "      <th>pause_duration</th>\n",
       "      <th>ipu_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>1.910</td>\n",
       "      <td>2.190</td>\n",
       "      <td>OK</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2.910</td>\n",
       "      <td>3.170</td>\n",
       "      <td>qu'est</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>4.210</td>\n",
       "      <td>4.280</td>\n",
       "      <td>ce</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>4.280</td>\n",
       "      <td>4.400</td>\n",
       "      <td>que</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.540</td>\n",
       "      <td>tu</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2692.425</td>\n",
       "      <td>2693.425</td>\n",
       "      <td>génial</td>\n",
       "      <td>True</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2693.605</td>\n",
       "      <td>2694.225</td>\n",
       "      <td>Nous</td>\n",
       "      <td>False</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2697.545</td>\n",
       "      <td>2697.905</td>\n",
       "      <td>avons</td>\n",
       "      <td>True</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2698.475</td>\n",
       "      <td>2698.865</td>\n",
       "      <td>terminé</td>\n",
       "      <td>True</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>bkt-pilot-221103-1-bas.TextGrid</td>\n",
       "      <td>ORT-MAU</td>\n",
       "      <td>2699.705</td>\n",
       "      <td>2700.585</td>\n",
       "      <td>bravo</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3397 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file     tier     start      stop     text  \\\n",
       "0     bkt-pilot-221103-1-bas.TextGrid  ORT-MAU     1.910     2.190       OK   \n",
       "1     bkt-pilot-221103-1-bas.TextGrid  ORT-MAU     2.910     3.170   qu'est   \n",
       "2     bkt-pilot-221103-1-bas.TextGrid  ORT-MAU     4.210     4.280       ce   \n",
       "3     bkt-pilot-221103-1-bas.TextGrid  ORT-MAU     4.280     4.400      que   \n",
       "4     bkt-pilot-221103-1-bas.TextGrid  ORT-MAU     4.400     4.540       tu   \n",
       "...                               ...      ...       ...       ...      ...   \n",
       "3392  bkt-pilot-221103-1-bas.TextGrid  ORT-MAU  2692.425  2693.425   génial   \n",
       "3393  bkt-pilot-221103-1-bas.TextGrid  ORT-MAU  2693.605  2694.225     Nous   \n",
       "3394  bkt-pilot-221103-1-bas.TextGrid  ORT-MAU  2697.545  2697.905    avons   \n",
       "3395  bkt-pilot-221103-1-bas.TextGrid  ORT-MAU  2698.475  2698.865  terminé   \n",
       "3396  bkt-pilot-221103-1-bas.TextGrid  ORT-MAU  2699.705  2700.585    bravo   \n",
       "\n",
       "      pause_duration  ipu_id  \n",
       "0              False       0  \n",
       "1               True       1  \n",
       "2               True       2  \n",
       "3              False       2  \n",
       "4              False       2  \n",
       "...              ...     ...  \n",
       "3392            True    1039  \n",
       "3393           False    1039  \n",
       "3394            True    1040  \n",
       "3395            True    1041  \n",
       "3396            True    1042  \n",
       "\n",
       "[3397 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: BAS seems to be messing up the alignment, being too (more than whisper) sensitive to echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54c6fdbc2999351b36885b0dc16fec3b775b1144f9b86f14b4f688ce9c011195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
